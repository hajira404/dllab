import nltk
from nltk import word_tokenize, pos_tag, ne_chunk

# Make sure NLTK resources are downloaded
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')
# Download the missing resource
nltk.download('maxent_ne_chunker_tab')

def extract_entities(text):
    entities = {'PERSON': [], 'LOCATION': []}

    # Step 1: Tokenize and POS tagging
    tokens = word_tokenize(text)
    pos_tags = pos_tag(tokens)

    # Step 2: Named Entity Chunking
    tree = ne_chunk(pos_tags, binary=False)

    # Step 3: Traverse the tree and extract Person and Location
    for subtree in tree:
        if hasattr(subtree, 'label'):
            if subtree.label() == 'PERSON':
                name = ' '.join([leaf[0] for leaf in subtree.leaves()])
                entities['PERSON'].append(name)
            elif subtree.label() == 'GPE':  # GPE = Geo-Political Entity (like cities, countries)
                location = ' '.join([leaf[0] for leaf in subtree.leaves()])
                entities['LOCATION'].append(location)

    return entities

# Example usage
text = "Barack Obama was born in Hawaii. Narendra Modi visited New York last year."
entities = extract_entities(text)

print("Persons:", entities['PERSON'])
print("Locations:", entities['LOCATION'])