import nltk
from nltk.wsd import lesk
from nltk.tokenize import word_tokenize
from nltk.corpus import wordnet

nltk.download('punkt')
nltk.download('wordnet')

sentences = [
    "The bank will not approve my loan.",
    "He sat on the river bank and enjoyed the view."
]

target_word = "bank"

for sentence in sentences:
    best_sense = lesk(word_tokenize(sentence), target_word)
    print(f"Sentence: {sentence}")
    print(f"Best Sense: {best_sense.name()} - {best_sense.definition()}\n")