import nltk
from nltk.tokenize import word_tokenize
from nltk import pos_tag

# Ensure required NLTK resources are downloaded
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
# Add the specific English resource download as suggested by the error
nltk.download('averaged_perceptron_tagger_eng')

# Sample text
text = "The cat sat on a mat"

# Step 1: Tokenize the sentence into words
words = word_tokenize(text)

# Step 2: Perform POS tagging
tagged_words = pos_tag(words)

# Step 3: Print the list of tagged words
print("Tagged Words:")
print(tagged_words)

# Step 4: Print each word with its POS tag
print("\nDetailed POS Tags:")
for word, tag in tagged_words:
    print(f"Word: {word}, POS Tag: {tag}")