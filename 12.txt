!pip install transformers datasets
import torch
from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline

model_name = "deepset/bert-base-cased-squad2"  
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForQuestionAnswering.from_pretrained(model_name)

qa_pipeline = pipeline("question-answering", model=model, tokenizer=tokenizer)

user_question = input("Enter your question: ")
user_context = input("Enter the context: ")

result = qa_pipeline(question=user_question, context=user_context)

print("Question:", user_question)
print("Answer:", result['answer'])