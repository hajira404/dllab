import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import string

# Download NLTK data
nltk.download('punkt')
nltk.download('stopwords')

# Sample text corpus (replace with your own text)
text = """
Natural Language Processing with Python is amazing. Python provides many libraries for text processing.
NLTK is one of the most popular libraries for text analysis and Natural Language Understanding.
"""

# Preprocessing: lowercase, remove punctuation
text = text.lower()
text = ''.join([char for char in text if char not in string.punctuation])

# Tokenization
tokens = word_tokenize(text)

# Remove stopwords
stop_words = set(stopwords.words('english'))
filtered_words = [word for word in tokens if word not in stop_words]

# Frequency distribution
freq_dist = nltk.FreqDist(filtered_words)

# Display top 10 frequent words
print("Top 10 Words:")
for word, freq in freq_dist.most_common(10):
    print(f"{word}: {freq}")

# Generate Word Cloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(freq_dist)

# Plot the Word Cloud
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.title("Word Cloud from Given Text Corpus")
plt.show()